[{"content":"Why Windows에서 Docker를 이용해 MySQL 이미지를 구동하던 중 한글이 깨지는 문제가 발생했습니다.\n볼륨으로 마운트한 *.cnf 파일에 characterset을 설정했지만, Windows에서는 이 파일이 777 권한으로 인식되면서 설정이 제대로 반영되지 않는 문제가 발생했습니다.\nWorld-writable config file \u0026#39;/etc/my.cnf\u0026#39; is ignored 여기서는 파일명을 my.cnf로 정의하겠습니다.\n[client] default-character-set = utf8mb4 [mysqld] authentication-policy = mysql_native_password 이 문제는 Windows와 Linux의 파일 시스템 차이에서 기인합니다.\nWindows에서 Docker를 사용하여 Linux 컨테이너 내의 볼륨으로 파일을 마운트할 때, 해당 파일의 권한 설정이 항상 일관적이지 않을 수 있습니다.\nToDo 이러한 문제를 해결하기 위해, 다음과 같은 접근 방법을 사용했습니다.\nDockerfile 작성 FROM mysql:8.0.30 COPY ./db/conf.d/my.cnf /etc/mysql/conf.d/my.cnf RUN chmod 644 /etc/mysql/conf.d/my.cnf MySQL의 기본 설정을 변경하기 위해 커스텀 Dockerfile을 만들었습니다. 이 파일을 통해 my.cnf 파일의 권한을 설정합니다. Docker Compose 파일 수정 version: \u0026#34;3.8\u0026#34; services: mysql: build: . ports: - \u0026#34;3306:3306\u0026#34; Custom image를 빌드하고 실행하기 위해 Docker Compose 파일을 수정했습니다. 이미지 빌드 및 컨테이너 실행 docker-compose up -d --build 새로운 Dockerfile을 이용해 이미지를 빌드하고 컨테이너를 실행합니다. ","date":"2023-11-18T21:36:30+09:00","image":"https://kjs92980.github.io/img/docker.png","permalink":"https://kjs92980.github.io/p/custom-configuration-to-mysql-in-windows/","title":"Windows에서 Docker 사용 시 MySQL 한글 깨짐 해결: Custom Configuration 적용하기"},{"content":"","date":"2023-08-26T21:21:10+09:00","image":"https://kjs92980.github.io/img/gitlab.png","permalink":"https://kjs92980.github.io/p/gitlab-ci-cd/","title":"Gitlab CI/CD 환경 구성"},{"content":"마이크로서비스 패턴 (크리스 리처드슨 저)의 7장 내용을 다룹니다. 마이크로서비스 아키텍처에서 쿼리를 작성할 때는 흩어져 있는 데이터를 검색해야하므로 어려울 수 있습니다. 이 장에서는 마이크로서비스 아키텍처에서 데이터를 쿼리하는 문제를 다음 방법으로 해결해 봅니다.\nAPI composition pattern API 조합 패턴 클라이언트가 각 서비스들을 호출하고 결과를 결합하는 책임을 지는 방식으로 동작합니다. Command query responsibility segregation 커맨드 쿼리 책임 분산 (CQRS) API Composition Pattern 모놀리식의 경우(데이터가 단일 데이터베이스에 저장되는 경우) 여러 개의 테이블을 조인하는 select문으로 쉽게 구현할 수 있습니다.\n하지만 마이크로서비스 기반의 애플리케이션에서는 데이터가 여러 서비스에 흩어져 있습니다. 주문 세부 정보가 필요한 모든 고객은 위 모든 서비스에 요청을 해야합니다.\nAPI composition pattern을 사용하면 이를 쉽게 구현할 수 있습니다.\nOverview API composer 클라이언트의 요청을 받아, 여러 Provider Services로부터 필요한 데이터를 가져오는 역할을 합니다. 이 데이터는 클라이언트가 필요로 하는 형식으로 조합되고, 이 조합된 데이터는 클라이언트에게 응답으로 반환됩니다. Provider Service API Composer로부터 요청을 받아, 해당 서비스가 가지고 있는 데이터나 기능을 반환하는 역할을 합니다. 이 서비스들은 독립적으로 운영되며 서로 다른 데이터와 기능을 가질 수 있습니다. 예제에서는 각 Provider service를 REST API 호출을 통해 결과를 가져오고 API composer에서 이를 조인하여 응답합니다.\n(물론 다른 통신 프로토콜을 사용하는 경우에도 사용할 수 있습니다.)\nDesign Issue 어떤 컴포넌트가 API composer가 될 것인가? 프론트엔드 클라이언트 API 게이트웨이 API composition 외에도 모든 마이크로 들어오는 요청을 통합적으로 관리하는 역할을 합니다. 독립된 서비스 (stand-alone application) 어떻게 효과적인 aggregation logic을 작성할지 느린 aggregation logic은 전체 시스템의 성능을 저하시키고, 클라이언트의 요청을 늦게 처리하는 결과를 초래할 수 있습니다. 이 과정에서 가능한 한 응답 시간을 최소화하기 위해 Provider services에 동시에 호출을 하는 것이 일반적입니다. 어떤 Provider service의 경우에는 다른 서비스들로부터의 결과가 필요한 경우가 있을 수 있습니다. 이렇게 병렬로 처리할 부분과 순차적으로 처리할 부분을 조합하는 방식은 복잡성을 증가시킵니다. 복잡성을 관리하기 위해 API composer은 reactive programming model을 사용하는 것이 좋습니다. Drawbacks 이 패턴은 마이크로서비스 아키텍처에서 쿼리 작업을 구현하는 간단하고 직관적인 방법이지만, 다음과 같은 단점이 있습니다.\n증가된 오버헤드 여러 개의 서비스를 호출하고 여러 데이터베이스에 쿼리를 날려야하므로 이로 인한 추가적인 리소스를 필요하게 됩니다. Availability 감소의 위험 API composer와 Provider services가 함께 동작해야하므로 전체 시스템의 가용성이 개인별 서비스 가용성보다 낮아질 수 있습니다. 하나의 서비스가 비정상 상태가 되면 그 서비스를 이용하는 API composition도 영향을 받게 되므로 가용성이 감소하는 문제가 발생할 수 있습니다. 가용성 감소 문제에 대해 몇 가지 개선 방법을 제시하고 있습니다.\nProvider service가 사용 불가능할 때 이전에 캐시된 데이터를 반환하는 방법입니다. 이 방법을 사용하면 가용성을 향상시킬 수 있지만, 반환된 데이터가 최신 상태가 아닐 수 있다는 문제점이 있습니다. API composer가 불완전한 데이터를 반환하는 방법입니다. 일부 서비스가 일시적으로 사용이 불가능하면 해당 데이터를 생략하고 나머지 데이터만 반환하는 것입니다. Transactional Data Consistency의 결여 모놀리식 애플리케이션엥서는 쿼리 연산을 하나의 데이터베이스 트랜잭션으로 실행하는 경우가 많습니다. 이는 일반적으로 애플리케이션에서 데이터의 일관된 뷰를 보장합니다. API composition pattern에서는 여러 데이터베이스에 대해 여러 쿼리를 실행합니다. 여기서 일관성이 없는 데이터를 반환하는 문제가 발생할 수 있습니다. 이 외에도 대량의 데이터셋에 대해 in-memory join을 수행해야하는 경우에는 API composition이 적합하지 않습니다. 메모리에 큰 양의 데이터를 저장하고 데이터를 처리하는데 상당한 리소스를 사용하기 때문에 성능 문제가 발생하거나 시스템이 전체적으로 느려질 수 있습니다.\nAPI composition pattern의 한계점을 극복하기 위해 CQRS 패턴을 사용할 수 있습니다.\nCQRS 패턴 CQRS는 커맨드와 쿼리의 책임을 분리하는 설계 패턴입니다.\nCommand: 상태 변경을 요청하는 작업입니다. 새 데이터를 추가하거나 기존 데이터를 업데이트하는 것이 이에 해당합니다. Query: 정보를 요청하는 작업입니다. 일반적으로 상태를 변경시키지 않고, 필요한 데이터를 조회하는 것에 해당합니다. Overview CQRS는 마이크로서비스 아키텍처에서 쿼리를 구현하는 다음 문제들의 해결책이 될 수 있습니다.\n비효율적인 in-memory join API composition patern의 in-memory join은 많은 양의 데이터를 처리해야 할 때는 비효율적일 수 있습니다. 지원하지 않는 데이터베이스나 형식 서비스가 데이터를 효율적인 쿼리를 지원하지 않는 데이터베이스에 저장하고 있을 수 있습니다. 이는 쿼리를 수행하는데 추가적인 시간이나 리소스를 필요로 할 수 있습니다. 관심사 분리 원칙 복잡한 쿼리가 필요한 경우 데이터를 가진 서비스에서 직접 쿼리하는 것이 적합하지 않을 수 있습니다. non-CQRS 일반적으로 CRUD 작업이 도메인 모델(데이터베이스에 매핑)을 통해 실행됩니다. 하나의 데이터 모델이 커맨드(데이터 변경 작업)과 쿼리(데이터 조회 작업)을 모두 지원합니다. CQRS 커맨드와 쿼리로 나뉘며, 커맨드 도메인 모델은 CRUD 작업을 처리하고 별도의 데이터베이스에 매핑이 됩니다. 데이터가 변경될 때마다 도메인 이벤트를 발행합니다. 쿼리 사이드는 복잡한 쿼리를 처리하는 별도의 모델을 말합니다. 지원하는 쿼리 유형에 가장 적합한 데이터베이스를 사용합니다. 이벤트 핸들러를 가져 커맨드 사이드에서 발행한 이벤트를 구독하고 이에 따라 데이터베이스를 업데이트합니다. 쿼리 처리 성능을 향상시키는 데 검색 엔진과 같은 도구를 사용할 수 있습니다. Benefits 마이크로서비스 아키텍처에서의 효율적인 쿼리 구현이 가능합니다. 기존의 API 조합 패턴에서는 메모리 내에서 데이터를 조인하는데 비효율적일 수 있습니다. CQRS는 서비스 간의 데이터를 미리 조인한 형태로 보관하고, 쿼리할 때 이를 활용하여 효율적인 쿼리를 가능하게 합니다. 다양한 쿼리의 구현이 가능합니다. 특정 쿼리를 효율적으로 구현하는 하나 이상의 뷰를 정의합니다. 이벤트 소싱 기반 애플리케이션에서의 쿼리가 가능합니다. 이벤트 소싱(Event Sourcing)은 상태 변경을 이벤트라는 일련의 변경 로그로 저장하는 방법론입니다. 이벤트 소싱은 시스템의 상태를 변경하는 모든 행동을 이벤트로 캡처하며, 이벤트는 순서대로 저장되고, 이러한 이벤트의 시퀀스로 시스템의 상태를 재현하거나 재생성할 수 있습니다. 이 방법은 비즈니스 요구 사항이 변해도 시스템이 그 변화에 대응할 수 있게 만들어주며, 언제 어떤 이벤트가 발생했는지에 대한 완벽한 기록을 제공합니다. 그러나 이벤트 소싱의 한계 중 하나는 이벤트 저장소(Event Store)가 기본 키에 기반한 쿼리만 지원한다는 것입니다. 즉, 특정 키를 사용해 직접적인 조회를 할 수 있지만, 그 외의 복잡한 쿼리나 조건을 통한 검색은 어렵습니다. CQRS를 이벤트 소싱과 함께 사용하면, 애플리케이션은 \u0026lsquo;Aggregates\u0026rsquo;의 \u0026lsquo;View\u0026rsquo;를 정의하고, 그 뷰는 이벤트 소싱 기반의 집합체가 발행하는 이벤트 스트림을 구독하며 업데이트됩니다. Aggregates는 도메인 모델의 일부를 나타내며, 그 상태는 이벤트를 통해 변경됩니다. 이렇게 만들어진 뷰는 여러 가지 복잡한 쿼리를 처리할 수 있게 해주므로, 이벤트 소싱을 기반으로 한 애플리케이션에서 복잡한 쿼리를 가능하게 합니다. 관심사의 분리 개선 CQRS가 하나의 서비스 내에서 \u0026lsquo;커맨드\u0026rsquo;과 \u0026lsquo;쿼리\u0026rsquo;를 처리하는 부분을 분리함으로써 서비스의 복잡성을 줄이고 유지보수를 용이하게 한다는 것을 의미합니다. 예를 들어, 커맨드는 비즈니스 로직을 처리하고 쿼리는 데이터 조회를 처리하게 됩니다. 이렇게 분리함으로써 각 부분은 자신의 역할에만 집중할 수 있게 됩니다. 데이터를 소유한 서비스와 쿼리를 구현하는 서비스를 분리가 가능합니다. CQRS를 이용하면 \u0026lsquo;데이터를 소유하는 서비스\u0026rsquo;와 \u0026lsquo;쿼리를 실행하는 서비스\u0026rsquo;가 서로 다른 서비스로 분리될 수 있다는 것을 의미합니다. 예를 들어, \u0026lsquo;주문 데이터\u0026rsquo;를 소유한 주문 서비스와 주문 조회를 처리하는 주문 조회 서비스가 별도로 존재할 수 있습니다. 이렇게 분리하면 특정 서비스의 부하가 다른 서비스에 영향을 미치는 것을 방지하고, 각 서비스를 독립적으로 확장할 수 있게 됩니다. Drawbacks 아키텍처의 복잡성이 증가합니다. 데이터를 갱신하고 쿼리하는 쿼리-사이드 서비스를 추가로 구현해야 하며, 이로 인해 추가적인 운영 복잡성이 발생할 수 있습니다. 여러 타입의 데이터베이스를 사용하게 되어 더 많은 복잡성을 더하게 됩니다. 커맨드, 쿼리 간의 지연이 있을 수 있습니다. 커맨드 사이드에서 이벤트를 발행하고 쿼리 사이드에서 이를 처리하여 뷰를 업데이트하는 사이에는 약간의 지연이 있을 수 있습니다. 불일치를 사용자에게 노출하지 않도록 지연되는 부분을 고려해서 구현해야 합니다. Designing Views View Data Store 선택 SQL 트랜잭션과 쿼리 기능이 잘 구성되어 있으나 데이터 모델이 비교적 유연하지 않아 요구 사항을 만족시키는 데 어려움이 있을 수 있습니다. NoSQL 트랜잭션 및 일반 쿼리 기능이 제한적이지만 CQRS 뷰는 간단한 트랜잭션과 고정된 쿼리만 실행하기 때문에 제한 사항에 크게 영향을 받지 않습니다. NoSQL는 유연한 데이터 모델과 더 나은 성능 및 확장성을 강점으로 CQRS 뷰에 적용할 수 있습니다. 책에 나오는 AWS DynamoDB는 NoSQL 서비스입니다. 두 개 이상의 서비스가 발행사는 이벤트를 구독하고 그에 따라 뷰를 업데이트해야하는 경우도 있습니다. 이 경우 외래 키를 기반으로 데이터를 업데이트해야 할 수 있습니다. NoSQL의 경우 기본 키를 사용한 연산에 최적화되어 있기 때문에 외래 키 기반의 업데이트를 위한 추가 구현이 필요할 수 있습니다. Data access 모듈 동시 업데이트 여러 aggregate types에서 발행하는 이벤트를 구독하는 경우, 여러 이벤트 핸들러가 동시에 동일한 레코드를 업데이트할 수 있습니다. 하나의 업데이트가 다른 업데이트를 덮어쓰는 것을 허용할 수는 없으므로 pessimistic locking 또는 optimistic locking을 사용하여 이를 해결할 수 있습니다. pessimistic locking: 데이터를 읽은 후 변경하기 전에 레코드에 락을 걸어 다른 트랜잭션들이 해당 레코드를 변경할 수 없도록 합니다. 이를 통해 동시에 레코드를 변경하려는 다른 트랜잭션의 개입을 막아 데이터 충돌을 방지합니다. optimistic locking: 레코드를 읽을 때 락을 걸지 않습니다. 대신, 레코드를 업데이트하는 시점에 그 레코드가 마지막으로 읽은 이후에 변경되지 않았는지 확인합니다. 이 값이 변경된 경우 충돌이 발생했음을 알리고 해당 트랜잭션을 롤백합니다. 멱등성(idempotency) 같은 이벤트를 여러 번 받을 수 있는데, 이 경우 일반적으로 쿼리 측 이벤트 핸들러가 멱등하다면 문제가 되지 않습니다. 이벤트 핸들러가 멱등하지 않는 경우 신뢰성을 유지하기 위해 이벤트 ID를 기록하고 데이터 저장소를 atmoically 업데이트해야 합니다. 최종적 일관성(eventual consistency) 불가피한 지연 문제(replication lag)로 클라이언트가 업데이트한 내용을 즉시 쿼리로 볼 수 없는 경우가 있습니다. 이를 위해 커맨드와 쿼리 모듈은 클라이언트가 불일치를 감지할 수 있도록 지원해야 합니다. CQRS 뷰 추가 및 업데이트 새로운 쿼리를 지원하기 위해 새로운 뷰를 추가하거나 스키마가 변경되었거나 뷰를 업데이트하는 코드에 버그를 수정해야해서 뷰를 재생성해야 할 때가 있습니다. 이때 다음과 같은 내용을 고려해야 합니다.\n아카이빙된 이벤트를 이용하여 뷰를 구축합니다. 메시지 브로커는 메시지를 무기한으로 저장할 수 없습니다. 그 이전의 이벤트도 읽기 위해 메시지 브로커와 별도로 아카이빙된 이벤트를 읽어서 뷰를 구축합니다. 시간이 지남에 따라 점점 모든 이벤트를 처리하는데 비용이 많이 들게 됩니다. two-step incremental algorithm으로 해결할 수 있습니다. Snapshot Creation: 이 단계에서는 각 aggregate instance의 스냅샷을 주기적으로 계산합니다. 이는 이전 스냅샷과 그 이후에 발생한 이벤트를 기반으로 합니다. 이렇게 하면 각 aggregate instance의 상태를 빠르게 알 수 있게 됩니다. 이렇게 생성된 스냅샷은 일종의 체크포인트 역할을 합니다. View Building: 이 단계에서는 스냅샷과 그 이후에 발생한 이벤트를 사용하여 뷰를 생성합니다. 이로써 뷰는 최신 상태로 업데이트됩니다. 이 알고리즘의 장점은 모든 이벤트를 처음부터 다시 처리할 필요 없이 뷰를 업데이트할 수 있다는 것입니다. 대신, 가장 최근의 스냅샷에서 시작하여 이후에 발생한 이벤트만 처리하면 됩니다. 이는 뷰를 업데이트하는 데 필요한 시간과 리소스를 크게 줄여줍니다. 참조 마이크로서비스 패턴 - 크리스 리처드슨 저 Microservice Architecture \u0026gt; Pattern: API Composition Microservice Architecture \u0026gt; Command Query Responsibility Segregation (CQRS) ","date":"2023-07-09T15:46:37+09:00","image":"https://kjs92980.github.io/p/implementing-queries-in-microservice/microservice-patterns_hu01dd3f6d24e8ce4d9f2d0e89cd14b66b_971642_120x120_fill_box_smart1_3.png","permalink":"https://kjs92980.github.io/p/implementing-queries-in-microservice/","title":"마이크로서비스 패턴 7장 마이크로서비스 쿼리 구현"},{"content":"Why? Node.js에서 console에 내장된 전역 객체로 표준 출력 또는 표준 에러 출력으로 로그를 기록하는데 사용합니다. console.log() 또는 console.error()로 출력한 로그는 Node.js application이 실행되는 콘솔에 바로 출력되므로, application이 종료되면 로그는 사라집니다. 리다이렉션(\u0026rsquo;\u0026gt;\u0026rsquo;)을 사용하여 파일로 리다이렉트를 할 수는 있지만 로그 레벨이나 형식을 설정하거나, 로그 파일을 자동으로 rotate하는 등의 기능은 제공하지 않습니다. 우리는 Winston과 같은 로깅 모듈을 사용하여 효과적으로 로그를 파일로 관리할 수 있습니다. 로그 레벨, 형식, transport, rotate 이 글에서는 Winston으로 사용해서 Node.js application의 로그를 특정 위치에 저장해보고,\nDocker container로 실행시킬 때 Volume을 사용하여 로컬 호스트에도 로그 파일이 저장되도록 설정해보겠습니다.\nInstall npm install winston Use const winston = require(\u0026#39;winston\u0026#39;); const logger = winston.createLogger({ transports: [ new winston.transports.Console() ] }); logger.info(\u0026#39;Hello world\u0026#39;); // {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;Hello world\u0026#34;} format format은 로그 메시지의 출력 포맷을 결정합니다. winston.format 모듈은 로그 메시지에 대한 사전 설정된 포맷을 사용할 수도 있고 사용자가 정의한 포맷을 사용할 수도 있습니다. winston.format.combine으로 여러 포맷을 하나의 포맷으로 결합할 수도 있습니다.\nconst logger = winston.createLogger({ format: winston.format.combine( winston.format.label({label: \u0026#39;service\u0026#39;}), winston.format.timestamp({ format: \u0026#39;YYYY-MM-DDTHH:mm:ss.SSSZ\u0026#39; }), winston.format.printf(({level, message, label, timestamp}) =\u0026gt; { return `${timestamp} [${label}] ${level}: ${message}` }) ), transports: [ new winston.transports.Console() ], }); logger.info(\u0026#39;Hello world\u0026#39;); // 2023-01-01T12:00:00.000+09:00 [service] info: Hello world label: 각 메시지에 사용자가 정의한 필드를 추가합니다. timestamp: 메시지를 받은 timestamp를 추가합니다. timestamp의 format도 정의할 수 있습니다. printf: 메시지의 최종 출력을 정의합니다. transports 로그 메시지가 출력되는 위치를 결정합니다. 로그 파일, 콘솔, 외부 서버 등이 될 수 있고, 여러 개의 transport를 동시에 사용하여 동시에 다른 위치에 메시지를 출력할 수 있습니다.\nconst logger = winston.createLogger({ format: winston.format.combine( winston.format.label({label: \u0026#39;service\u0026#39;}), winston.format.timestamp({ format: \u0026#39;YYYY-MM-DDTHH:mm:ss.SSSZ\u0026#39; }), winston.format.printf(({level, message, label, timestamp}) =\u0026gt; { return `${timestamp} [${label}] ${level}: ${message}` }) ), transports: [ new winston.transports.File({ filename: \u0026#39;service.log\u0026#39;}), ], }); logger.info(\u0026#39;Hello world\u0026#39;); // 2023-01-01T12:00:00.000+09:00 [service] info: Hello world 위 예제에서는 \u0026lsquo;service.log\u0026rsquo; 파일로 출력하고 있습니다. 이렇게 하면 해당 한 파일에 로그가 계속 쌓이게 되는데 로그 파일의 rotation은 파일이 무제한으로 커지는 것을 방지할 수 있습니다. 우리는 winston-daily-rotate-file을 사용해서 파일 rotation을 설정해보겠습니다.\nimport DailyRotateFile from \u0026#39;winston-daily-rotate-file\u0026#39;; const logger = winston.createLogger({ format: winston.format.combine( winston.format.label({label: \u0026#39;service\u0026#39;}), winston.format.timestamp({ format: \u0026#39;YYYY-MM-DDTHH:mm:ss.SSSZ\u0026#39; }), winston.format.printf(({level, message, label, timestamp}) =\u0026gt; { return `${timestamp} [${label}] ${level}: ${message}` }) ), transports: [ new DailyRotateFile({ filename: \u0026#39;service.log\u0026#39;, datePattern: \u0026#39;YYYY-MM-DD_HH\u0026#39;, maxSize: \u0026#39;20m\u0026#39;, maxFiles: \u0026#39;7d\u0026#39;, }) ], }); // 파일명 service.log.2023-01-01_12 filename: 로깅에 사용할 파일 이름입니다. dataPattern: rotation에 사용할 moment.js 날짜 포맷을 나타냅니다. maxSize: rotation할 파일의 최대 크기입니다. 파일의 크기가 maxSize에 도달하면 새로운 파일이 생성됩니다. maxFiles: 보관할 최대 파일 개수, 일수를 말합니다. 예제의 경우 7일이 경과하면 자동으로 파일이 삭제됩니다. 이 외에도 zippedArchive 옵션으로 로그 파일을 압축할 수도, level로 로깅 레벨을 설정할 수도 있습니다. 서버 application에서는 access 로그(incoming request에 대한 로그)도 파일로 기록하면 좋겠죠.\nMorgan을 winston logger과 함께 사용하면 winston의 기능을 사용해서 로그를 잘 관리할 수 있습니다.\nMorgan Morgan은 HTTP request 로그 미들웨어로 요청, 응답에 대한 정보를 로그로 남길 수 있습니다. 다양한 출력 포맷과 로그 레벨, rotation, 압축을 사용하기 위해 winston 모듈과 함께 사용해보도록 합시다.\nconst accessLogger = winston.createLogger({ format: winston.format.combine( winston.format.timestamp({ format: \u0026#39;YYYY-MM-DDTHH:mm:ss.SSSZ\u0026#39; }), winston.format.printf(info =\u0026gt; { let message = info.message; if (typeof message === \u0026#39;object\u0026#39;) { Object.assign(info, message); delete info.message; } return JSON.stringify(info); }), ), transports: [ new DailyRotateFile({ filename: \u0026#39;access.log\u0026#39;, datePattern: \u0026#39;YYYY-MM-DD_HH\u0026#39;, maxSize: \u0026#39;20m\u0026#39;, maxFiles: \u0026#39;7d\u0026#39;, }) ], }); morgan.format(\u0026#39;json\u0026#39;, (tokens, req, res) =\u0026gt; { return JSON.stringify({ \u0026#39;ip\u0026#39;: tokens[\u0026#39;remote-addr\u0026#39;](req, res), \u0026#39;method\u0026#39;: tokens.method(req, res), \u0026#39;url\u0026#39;: tokens.url(req, res), \u0026#39;status\u0026#39;: tokens.status(req, res), \u0026#39;contentLength\u0026#39;: tokens.res(req, res, \u0026#39;content-length\u0026#39;), \u0026#39;duration\u0026#39;: tokens[\u0026#39;response-time\u0026#39;](req, res), \u0026#39;version\u0026#39;: \u0026#39;HTTP/\u0026#39; + tokens[\u0026#39;http-version\u0026#39;](req, res), \u0026#39;host\u0026#39;: tokens.req(req, res, \u0026#39;hostname\u0026#39;), }); }); const accessStream = { write: message =\u0026gt; { const {ip, method, url, status, contentLength, duration, proto, host} = JSON.parse(message); accessLogger.info({ip, method, url, status, contentLength, duration, proto, host}); } }; const app = express(); app.use(morgan(\u0026#39;json\u0026#39;, {stream: accessStream})); // {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2023-01-01T00:00:00.000+09:00\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;127.0.0.1\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;GET\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;/health\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;200\u0026#34;,\u0026#34;duration\u0026#34;:\u0026#34;4.900\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;HTTP/1.1\u0026#34;} write()을 포함한 accessStream을 구현하여 morgan에 설정을 해줍니다. accessLogger.info()로 추가하게 되면 message의 필드들로 들어가게 되는데 message 밖으로 필드를 꺼내기 위해 winston.format.printf를 정의했습니다. 예제에서는 \u0026lsquo;json\u0026rsquo;이라는 포맷을 사용자가 정의했지만 이미 정의된 \u0026rsquo;tiny\u0026rsquo;, \u0026lsquo;short\u0026rsquo;, \u0026lsquo;common\u0026rsquo; 등으로 설정하여 보다 간단하게 설정할 수도 있습니다.\nDocker Volumes express application을 docker container로 실행하면 이 container가 down했을 때 로그 파일도 제거됩니다. 매번 새로운 버전으로 업데이트할 때마다 로그 파일이 제거되면 서비스 운영이 어려움이 있을 것입니다. 이를 방지하기 위해 중요한 로그 데이터는 외부 볼륨에 저장하거나, 별도의 로그 관리 시스템에서 수집할 수 있습니다.\n우리는 docker volumes을 통해 호스트 시스템 디렉토리에 마운트해서 container가 down되더라도 로그 파일이 유지될 수 있도록 설정해보겠습니다.\nversion: \u0026#34;3.8\u0026#34; services: backend: container_name: backend image: backend:${TAG} ports: - \u0026#34;8080:8080\u0026#34; volumes: - /local/path/log:/container/path/log 호스트(로컬) 경로인 \u0026lsquo;/local/path/log\u0026rsquo;를 컨테이너 내부 경로인 \u0026lsquo;/container/path/log\u0026rsquo;와 연결하고, 호스트의 로그 파일을 컨테이너의 로그 경로로 마운트합니다.\n이를 통해 로컬 파일 시스템과 컨테이너 간에 데이터를 공유하고, 컨테이너 내부에서 해당 경로에 액세스할 수 있습니다.\n이제는 container가 down되더라도 \u0026lsquo;/local/path/log\u0026rsquo;에 로그 파일이 남아 조회해볼 수 있습니다.\nConclusion Node.js에서 winston이라는 사용자 정의 포맷, rotation, 압축 등을 지원하는 로깅 모듈을 통해 다양한 경로로 출력할 수 있습니다. HTTP request, response를 기록하는 morgan도 winston과 함께 사용하면 위 기능들로 로그 파일을 관리할 수 있습니다. docker container로 application을 운영하는 경우 volumes로 로그 파일을 호스트에 마운트하면 container down 시에도 호스트에 로그 파일을 유지할 수 있습니다. 참조 Github: Winston Github: winston-daily-rotate-file Github: Morgan Docker Docs \u0026gt; Volumes ","date":"2023-06-18T13:26:26+09:00","image":"https://kjs92980.github.io/img/node.png","permalink":"https://kjs92980.github.io/p/node-logs-winston/","title":"Node.js Express Winston 사용하여 로깅하기"},{"content":"Random I/O vs Sequential I/O Random I/O\n디스크에 무작위로 위치한 데이터를 읽고 쓰는 것을 말합니다. 디스크 헤드가 물리적으로 디스크의 여러 위치로 이동해야 하기 때문에 일반적으로 느립니다. Sequential I/O\n디스크의 특정 영역에 연속적으로 위치한 데이터를 읽고 쓰는 것을 말합니다. 디스크 헤드가 물리적으로 연속된 위치로만 이동하면 되므로 일반적으로 빠르고 효율적입니다. 우리는 Random I/O의 횟수를 줄이는 방향으로, 즉 꼭 필요한 데이터만 읽도록 쿼리를 개선해야 합니다.\nIndex 인덱스가 없는 상태에서는 특정 쿼리를 수행하기 위해 전체 데이터를 훑어야 하므로 이는 크게 Random I/O를 초래합니다. 디스크 헤드는 모든 데이터 블록을 무작위로 방문해야 하기 때문입니다.\n반면에, 인덱스가 존재하는 경우, 인덱스를 사용해 필요한 데이터를 빠르게 찾을 수 있습니다. 디스크의 연속된 영역에 위치한 인덱스 블록을 순차적으로 읽음으로써 Sequential I/O가 가능하게 합니다.\n위에서 말한 Random I/O를 줄이는 방법으로 사용할 수 있다는 것입니다.\n(물론 Non-Clustered Index에서 주소가 가르키는 데이터를 가져오는 작업은 random I/O로 분류됩니다.)\nClustered Index db.createCollection(\u0026#34;collection\u0026#34;,{ clusteredIndex: { \u0026#34;key\u0026#34;: { _id: 1 }, \u0026#34;unique\u0026#34;: true, \u0026#34;name\u0026#34;: \u0026#34;clustered key\u0026#34; } }); MongoDB 5.3부터는 clustered index를 가진 컬렉션을 생성할 수 있게 되었습니다.\n일반 인덱스와 가장 다른 차이점은 인덱스 키의 순서대로 인덱스와 데이터가 물리적으로 저장된다는 것입니다.\n(일반 인덱스는 참조를 사용해서 데이터 위치를 가르킵니다.)\n그러므로 clustered index는 별도의 인덱스 저장 공간이 필요 없습니다.\ninsert, update, delete 시 _id 인덱스에 별도 쓰기가 필요 없으므로 한번의 쓰기만을 필요로 합니다. 특히 range query에서 유용합니다. 인덱스 키의 순서에 따라 물리적으로 저장된 데이터를 순차적으로 읽을 수 있게 됩니다. insert 시 데이터가 순서대로 저장을 해야하기 때문에 추가적인 I/O 작업이 있을 수 있습니다. 문서에서는 _id에 sequantial한 키를 포함하는 것을 권장합니다. None-Clustered Index Primary index, Secondary index와 같이 clustered index가 아닌 인덱스를 말합니다.\n동작 방식 *WiredTiger 스토리지 엔진에서는 기본적으로 B-Tree 기반의 인덱싱 알고리즘을 사용하고 있습니다.\nB-Tree 인덱스는 데이터를 물리적으로 정렬된 방식으로 저장하지는 않지만, 정렬된 키와 그 키에 연관된 데이터의 물리적 주소를 가지고 있습니다. 인덱스 키를 추가할 때는 B-Tree의 리프노드에 값을 추가하고 데이터가 저장된 위치를 저장합니다.\n테이블에 레코드를 추가하는 작업의 비용이 1, 1개의 인덱스가 있다고 가정하면 2(1*1 + 1)정도의 비용이 든다고 대략적으로 예측할 수 있습니다. 인덱스 키를 삭제할 때는 해당 키 값을 찾아서 삭제 마크를 합니다. 즉, 물리적으로 제거되는 것이 아니라, 삭제 마크를 사용하여 논리적으로 삭제된 것으로 표시합니다.\n마킹된 항목은 실제로 물리적으로 제거되거나 재사용될 수 있습니다.\n인덱스 키를 삭제하면 WiredTiger 스토리지 엔진은 Write-Ahead Log에 기록합니다. 실제 디스크에 이 변경 사항이 적용되는 시점은 syncPeriodSecs라는 설정으로 제어할 수 있습니다. 인덱스 키를 수정할 때는 먼저 키 값을 삭제하고 새로운 키 값을 추가하는 방식으로 처리됩니다. 인덱스 키를 검색할 때는 B-Tree의 루트 노드부터 최종 리프 노드까지 비교하는 과정을 통해서 이동합니다.\nB-Tree 인덱스를 이용한 검색은 100% 일치, 앞 부분 일치, 그리고 range query 등에 사용될 수 있습니다. 인덱스 키 값의 사이즈는 작을수록 좋습니다.\n키 값의 사이즈가 커지면 하나의 인덱스 페이지가 담을 수 있는 인덱스 키 값의 개수가 작아지고, 이에 따라 간접적으로 B-Tree의 깊이가 더 깊어질 수 있습니다. 이는 디스크 I/O가 늘어나게 되어 성능 저하를 가져올 수 있습니다. *WiredTiger 스토리지 엔진은 MongoDB 3.2부터 기본 엔진입니다.\n메모리 빠른 성능을 위해 인덱스가 RAM 용량 내에 들어가게 하는 전략을 취할 수 있습니다. (디스크에서 인덱스를 읽지 않도록) RAM에 들어갈 수 있는 인덱스의 양이 제한적이기 때문에, 인덱스의 크기가 RAM의 크기를 초과하면 MongoDB는 인덱스 데이터를 디스크에서 가져와야 합니다. 인덱싱된 필드의 값이 삽일될 때마다 증가하고 대부분의 쿼리가 최근에 추가된 문서를 선택하는 경우 가장 최근을 포함하는 인덱스 부분만 RAM에 유지하면 됩니다. TTL Index db.collection.createIndex( { \u0026#34;createdDate\u0026#34;: 1 }, { expireAfterSeconds: 3600} ); 특정 시간이 지나면 컬렉션에서 문서를 자동으로 제거하는 Index입니다.\nTTL 인덱스로 데이터를 삭제하는 작업은 주로 오래된 데이터(메모리에 캐시되지 않은 데이터)가 될 가능성이 높은데, 이 경우 디스크를 읽어서 처리해야하는 경우가 많습니다. TTL Monitor라는 별도의 백그라운드에서 도는 thread에서 동작합니다. 용량이 크거나 많은 인덱스를 가진 컬렉션에서 많은 도큐먼트가 삭제된다면 많은 디스크의 I/O를 유발하고 복제 지연을 발생시킬 수 있습니다. (도큐먼트와 연결된 인덱스 키도 모두 제거되어져야하기 때문입니다.) Conclusion 인덱스를 사용하면 쿼리의 성능 등을 향상시킬 수 있습니다.\n그러나 인덱스를 저장하기 위해 상당한 디스크 공간을 사용할 수 있고, insert, update의 경우 인덱스를 위한 추가 작업으로 부하를 더할 수 있습니다.\napplication의 쿼리 패턴과 데이터 모델, 사용하는 서버 스펙(메모리, 디스크)을 고려하여 인덱스를 사용하는 것이 좋습니다.\n참조 MongoDB \u0026gt; Indexes Real MongoDB ","date":"2023-06-05T15:11:17+09:00","image":"https://kjs92980.github.io/img/mongodb.png","permalink":"https://kjs92980.github.io/p/mongodb-indexes/","title":"MongoDB 인덱스"},{"content":"이 글에서는 Windows에서 GNU Make를 설치하고 make 명령어를 사용해보겠습니다.\nMake Unix 계열 운영체제를 대상으로 만들어진 프로그램 빌드 도구를 말합니다.\nMakefile(빌드 자동화 스크립트 파일) 정의를 통해 복잡한 작업을 자동화 시킬 수 있습니다.\n강의에서는 Docker를 올리고 내리는 작업을 각각 정의하였습니다.\nWindows에서 이 명령어를 수행하기 위해서는 별도의 설치가 필요합니다.\nWindows용 intaller는 여기를 통해 다운로드 받을 수 있습니다.\n하지만 버전이 오래되기도 하고(3.81, 2006년 업데이트) 설치 후 환경 변수도 설정해줘야 해서 여기서는 Chocolatey를 통해 설치하겠습니다.\nChocolatey Windows에서 사용할 수 있는 커맨드 라인 패키지 관리자입니다.\nLinux의 yum, MacOS의 Homebrew를 생각하시면 됩니다.\nChoco의 설치 방법은 Installing Chocolatey에 자세히 설명되어 있습니다.\n함께 과정을 따라가봅시다.\nChocolatey 설치 먼저 PowerShell을 관리자로 실행합니다. Installing Chocolatey 내 다운로드 명령어를 복사 후 붙여넣기 해줍니다. Choco 설치가 완료되었습니다. choco또는 choco -?로 확인합니다. Make 설치 Choco를 통해 make를 설치하는 방법은 간단합니다. choco install make 설치가 완료되었습니다! 정의해둔 위치에서 make 명령어를 수행합니다. 마치며 Chocolatey를 통해 간단한 명령어로 패키지를 업데이트하거나 다른 패키지를 설치하는데 유용하게 사용할 수 있을 것입니다. Makefile에 자동화 할 동작이 있다면 추가로 정의해봐도 좋을 것 같습니다. 오늘도 좋은 하루 되세요. 감사합니다. 😁\n","date":"2023-01-15T17:45:00+09:00","image":"https://kjs92980.github.io/p/use-make-in-windows/gnu-make_hucda8a18b4517645f401d3697ff133257_885691_120x120_fill_box_smart1_3.png","permalink":"https://kjs92980.github.io/p/use-make-in-windows/","title":"Windows make 사용하기 (using Chocolatey)"},{"content":"h1 제목 h2 제목 h3 제목 h4 제목 리스트 1 리스트 2 리스트 3 코드블럭 package main import \u0026#34;fmt\u0026#34; func main(){ fmt.Println(\u0026#34;Hello World\u0026#34;) } ","date":"2022-01-01T00:00:00Z","image":"https://kjs92980.github.io/p/hello-world/cover_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://kjs92980.github.io/p/hello-world/","title":"Hello World"}]